# ==============================================
# Fluent Learner V2 - Backend Configuration
# ==============================================
# Copy this file to .env and fill in your values
# NEVER commit .env files with real credentials!

# ----------------------------------------------
# AI Provider Selection (Optional)
# ----------------------------------------------
# Uncomment to override auto-detection
# LLM_PROVIDER=azure        # Options: azure, openai, ollama
# WHISPER_PROVIDER=azure    # Options: azure, openai, local

# ----------------------------------------------
# Azure OpenAI Configuration
# ----------------------------------------------
# Get these from: https://portal.azure.com -> Azure OpenAI -> Keys and Endpoint
AZURE_OPENAI_ENDPOINT=https://YOUR_RESOURCE.openai.azure.com
AZURE_OPENAI_API_KEY=your_azure_api_key_here
AZURE_OPENAI_API_VERSION=2024-02-01

# Deployment names (must match your Azure deployments)
AZURE_OPENAI_DEPLOYMENT_CHAT=gpt-4o
AZURE_OPENAI_DEPLOYMENT_WHISPER=whisper

# ----------------------------------------------
# Standard OpenAI Configuration (Alternative)
# ----------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-your_openai_api_key_here
# OPENAI_MODEL_NAME=gpt-4o-mini
# OPENAI_WHISPER_MODEL=whisper-1

# ----------------------------------------------
# Ollama Configuration (Local LLM)
# ----------------------------------------------
# Install Ollama from: https://ollama.ai
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL_NAME=llama3

# ----------------------------------------------
# Local Whisper Configuration (Offline Transcription)
# ----------------------------------------------
# Uses faster-whisper for local speech-to-text
# Models are downloaded automatically on first use
# Set WHISPER_PROVIDER=local to enable

# Model options: tiny (75MB), base (142MB), small (466MB), medium (1.5GB), large-v3 (2.9GB)
# LOCAL_WHISPER_MODEL=base

# Device: auto (recommended), cuda (NVIDIA GPU), cpu
# LOCAL_WHISPER_DEVICE=auto

# Compute type: auto (recommended), float16 (GPU), int8 (CPU), float32
# LOCAL_WHISPER_COMPUTE_TYPE=auto

# Custom models directory (optional, defaults to app data folder)
# LOCAL_WHISPER_MODELS_DIR=/path/to/models
